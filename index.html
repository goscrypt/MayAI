<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>AI Chatbot with File Context</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            padding: 20px;
            max-width: 600px;
            margin: auto;
            background-color: #f0f2f5;
        }
        .container {
            background-color: white;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }
        h2 {
            color: #333;
            text-align: center;
        }
        #chatLog {
            width: 100%;
            height: 300px;
            margin-top: 10px;
            padding: 10px;
            font-family: monospace;
            border: 1px solid #ccc;
            border-radius: 4px;
            resize: none;
            box-sizing: border-box;
            background-color: #fafafa;
        }
        .input-group {
            display: flex;
            margin-top: 10px;
        }
        #userInput {
            flex-grow: 1;
            padding: 10px;
            border: 1px solid #ccc;
            border-radius: 4px;
        }
        #sendBtn {
            padding: 10px 20px;
            margin-left: 10px;
            background-color: #007bff;
            color: white;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            transition: background-color 0.3s;
        }
        #sendBtn:hover {
            background-color: #0056b3;
        }
        #fileInput {
            width: 100%;
            margin-top: 10px;
        }
        .loading-message {
            text-align: center;
            color: #555;
            margin-top: 10px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h2>📄 AI Chatbot with File Context</h2>
        <input type="file" id="fileInput" accept=".txt, .md, .csv">
        <textarea id="chatLog" readonly placeholder="Chat log will appear here..."></textarea>
        <div class="input-group">
            <input type="text" id="userInput" placeholder="Ask your question...">
            <button id="sendBtn">Send</button>
        </div>
        <div id="statusMessage" class="loading-message"></div>
    </div>

    <script type="module">
        import { pipeline, AutoTokenizer, AutoModel } from 'https://cdn.jsdelivr.net/npm/@xenova/transformers@2.5.1';

        let textGenerator;
        let sentenceEncoder;
        let fileContext = '';
        const chatLog = document.getElementById('chatLog');
        const fileInput = document.getElementById('fileInput');
        const userInput = document.getElementById('userInput');
        const sendBtn = document.getElementById('sendBtn');
        const statusMessage = document.getElementById('statusMessage');

        // This is a new, two-step model loading process
        async function initModels() {
            statusMessage.textContent = "⌛ Loading AI models...";
            sendBtn.disabled = true;

            // Load a model specifically for encoding sentences
            sentenceEncoder = await pipeline('feature-extraction', 'Xenova/all-MiniLM-L6-v2');
            
            // Load a model for generating text (our chatbot)
            textGenerator = await pipeline('text-generation', 'Xenova/distilgpt2');

            statusMessage.textContent = "✅ Models loaded successfully. You can now chat!";
            sendBtn.disabled = false;
        }

        fileInput.addEventListener('change', async (event) => {
            const file = event.target.files[0];
            if (file) {
                const text = await file.text();
                fileContext = text;
                chatLog.textContent += `📄 File loaded: ${file.name}\n\n`;
            }
        });

        // This is a helper function to calculate the similarity between two sentences
        function cosineSimilarity(a, b) {
            const dotProduct = a.reduce((sum, val, i) => sum + val * b[i], 0);
            const magnitudeA = Math.sqrt(a.reduce((sum, val) => sum + val * val, 0));
            const magnitudeB = Math.sqrt(b.reduce((sum, val) => sum + val * val, 0));
            return dotProduct / (magnitudeA * magnitudeB);
        }

        async function sendMessage() {
            if (!textGenerator || !sentenceEncoder) {
                await initModels();
            }

            const input = userInput.value.trim();
            if (!input) return;

            // Display user message immediately and clear input
            chatLog.textContent += `You: ${input}\n`;
            userInput.value = '';

            // Show a "typing" indicator
            statusMessage.textContent = "🤖 Bot is typing...";
            sendBtn.disabled = true;

            try {
                // Step 1: Smart Information Retrieval
                // We'll split the text file into individual sentences.
                const sentences = fileContext.split(/(?<!\w\.\w.)(?<![A-Z][a-z]\.)(?<=\.|\?|\!)\s/);
                
                // We'll encode the user's question and all sentences from the file.
                const queryEmbedding = await sentenceEncoder(input, { pooling: 'mean', normalize: true });
                const sentenceEmbeddings = await sentenceEncoder(sentences, { pooling: 'mean', normalize: true });

                // Find the most relevant sentence by comparing embeddings
                let maxSimilarity = -1;
                let mostRelevantSentence = '';
                for (let i = 0; i < sentences.length; i++) {
                    const similarity = cosineSimilarity(queryEmbedding.data, sentenceEmbeddings.data[i]);
                    if (similarity > maxSimilarity) {
                        maxSimilarity = similarity;
                        mostRelevantSentence = sentences[i];
                    }
                }

                // Step 2: Concise Generation
                // We'll create a new, concise prompt using ONLY the most relevant sentence.
                const prompt = `Based on this information: "${mostRelevantSentence}", answer the question: "${input}"`;

                const response = await textGenerator(prompt, {
                    max_new_tokens: 50, // Keep this low to force a concise answer
                    return_full_text: false,
                });

                let reply = response[0].generated_text.trim();

                // Final cleanup to remove any lingering prompt text
                const cleanRegex = /(Based on this information:.*answer the question:.*|Assistant:|\n)+/g;
                reply = reply.replace(cleanRegex, '').trim();

                chatLog.textContent += `Bot: ${reply}\n\n`;
                chatLog.scrollTop = chatLog.scrollHeight; // Auto-scroll to the bottom
            } catch (error) {
                chatLog.textContent += `Bot: ❌ An error occurred: ${error.message}\n\n`;
            } finally {
                statusMessage.textContent = "✅ Ready for your next question!";
                sendBtn.disabled = false;
            }
        }

        sendBtn.addEventListener('click', sendMessage);
        userInput.addEventListener('keypress', (event) => {
            if (event.key === 'Enter') {
                sendMessage();
            }
        });

        window.onload = initModels;
    </script>
</body>
</html>
